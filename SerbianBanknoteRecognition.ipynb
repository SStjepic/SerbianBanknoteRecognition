{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90f29f09",
   "metadata": {},
   "source": [
    "# Serbian Banknote Recognition\n",
    "**Autor:** Stefan Stjepić SV40/2022  \n",
    "**Predmet:** Računarska inteligencija  \n",
    "**Cilj:** Razvoj sistema koji **automatski prepoznaje srpske novčanice** kombinacijom *detekcije (YOLOv8)* i *klasifikacije (CNN)*.\n",
    "\n",
    "Ovaj notebook demonstrira ceo tok projekta:\n",
    "1. Priprema i pretprocesiranje dataset-a za treniranje YOLOv8 modela  \n",
    "2. Treniranje YOLOv8 modela za detekciju novčanica  \n",
    "3. Priprema i pretprocesiranje dataset-a za treniranje CNN modela \n",
    "4. Treniranje CNN modela za klasifikaciju apoena  \n",
    "5. Kombinovanje YOLO + CNN modela za prepoznavanje srpskih novčanica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c5f19",
   "metadata": {},
   "source": [
    "## 1. Priprema i pretprocesiranje dataset-a za treniranje YOLOv8 modela\n",
    "\n",
    "Dataset: [Serbian Banknotes - Kaggle](https://www.kaggle.com/datasets/stefanstjepic/serbian-banknotes)\n",
    "\n",
    "Sadrži:\n",
    "- 270 slika -> 30 po apoenu [10, 20, 50, 100, 200, 500, 1000, 2000, 5000], 15 po strani\n",
    "- YOLO label -> .txt fajlovi koji sadrže podatke oblika\n",
    "```bash\n",
    "        <class_id> <x_center> <y_center> <width> <height>\n",
    "```\n",
    "\n",
    "Koraci obrade:\n",
    "- Resize na 512x512\n",
    "- Podela na train/val/test (70/15/15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea0af0b",
   "metadata": {},
   "source": [
    "### Skripta za pretprocesiranje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "250fe01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/270\n",
      "2/270\n",
      "3/270\n",
      "4/270\n",
      "5/270\n",
      "6/270\n",
      "7/270\n",
      "8/270\n",
      "9/270\n",
      "10/270\n",
      "11/270\n",
      "12/270\n",
      "13/270\n",
      "14/270\n",
      "15/270\n",
      "16/270\n",
      "17/270\n",
      "18/270\n",
      "19/270\n",
      "20/270\n",
      "21/270\n",
      "22/270\n",
      "23/270\n",
      "24/270\n",
      "25/270\n",
      "26/270\n",
      "27/270\n",
      "28/270\n",
      "29/270\n",
      "30/270\n",
      "31/270\n",
      "32/270\n",
      "33/270\n",
      "34/270\n",
      "35/270\n",
      "36/270\n",
      "37/270\n",
      "38/270\n",
      "39/270\n",
      "40/270\n",
      "41/270\n",
      "42/270\n",
      "43/270\n",
      "44/270\n",
      "45/270\n",
      "46/270\n",
      "47/270\n",
      "48/270\n",
      "49/270\n",
      "50/270\n",
      "51/270\n",
      "52/270\n",
      "53/270\n",
      "54/270\n",
      "55/270\n",
      "56/270\n",
      "57/270\n",
      "58/270\n",
      "59/270\n",
      "60/270\n",
      "61/270\n",
      "62/270\n",
      "63/270\n",
      "64/270\n",
      "65/270\n",
      "66/270\n",
      "67/270\n",
      "68/270\n",
      "69/270\n",
      "70/270\n",
      "71/270\n",
      "72/270\n",
      "73/270\n",
      "74/270\n",
      "75/270\n",
      "76/270\n",
      "77/270\n",
      "78/270\n",
      "79/270\n",
      "80/270\n",
      "81/270\n",
      "82/270\n",
      "83/270\n",
      "84/270\n",
      "85/270\n",
      "86/270\n",
      "87/270\n",
      "88/270\n",
      "89/270\n",
      "90/270\n",
      "91/270\n",
      "92/270\n",
      "93/270\n",
      "94/270\n",
      "95/270\n",
      "96/270\n",
      "97/270\n",
      "98/270\n",
      "99/270\n",
      "100/270\n",
      "101/270\n",
      "102/270\n",
      "103/270\n",
      "104/270\n",
      "105/270\n",
      "106/270\n",
      "107/270\n",
      "108/270\n",
      "109/270\n",
      "110/270\n",
      "111/270\n",
      "112/270\n",
      "113/270\n",
      "114/270\n",
      "115/270\n",
      "116/270\n",
      "117/270\n",
      "118/270\n",
      "119/270\n",
      "120/270\n",
      "121/270\n",
      "122/270\n",
      "123/270\n",
      "124/270\n",
      "125/270\n",
      "126/270\n",
      "127/270\n",
      "128/270\n",
      "129/270\n",
      "130/270\n",
      "131/270\n",
      "132/270\n",
      "133/270\n",
      "134/270\n",
      "135/270\n",
      "136/270\n",
      "137/270\n",
      "138/270\n",
      "139/270\n",
      "140/270\n",
      "141/270\n",
      "142/270\n",
      "143/270\n",
      "144/270\n",
      "145/270\n",
      "146/270\n",
      "147/270\n",
      "148/270\n",
      "149/270\n",
      "150/270\n",
      "151/270\n",
      "152/270\n",
      "153/270\n",
      "154/270\n",
      "155/270\n",
      "156/270\n",
      "157/270\n",
      "158/270\n",
      "159/270\n",
      "160/270\n",
      "161/270\n",
      "162/270\n",
      "163/270\n",
      "164/270\n",
      "165/270\n",
      "166/270\n",
      "167/270\n",
      "168/270\n",
      "169/270\n",
      "170/270\n",
      "171/270\n",
      "172/270\n",
      "173/270\n",
      "174/270\n",
      "175/270\n",
      "176/270\n",
      "177/270\n",
      "178/270\n",
      "179/270\n",
      "180/270\n",
      "181/270\n",
      "182/270\n",
      "183/270\n",
      "184/270\n",
      "185/270\n",
      "186/270\n",
      "187/270\n",
      "188/270\n",
      "189/270\n",
      "190/270\n",
      "191/270\n",
      "192/270\n",
      "193/270\n",
      "194/270\n",
      "195/270\n",
      "196/270\n",
      "197/270\n",
      "198/270\n",
      "199/270\n",
      "200/270\n",
      "201/270\n",
      "202/270\n",
      "203/270\n",
      "204/270\n",
      "205/270\n",
      "206/270\n",
      "207/270\n",
      "208/270\n",
      "209/270\n",
      "210/270\n",
      "211/270\n",
      "212/270\n",
      "213/270\n",
      "214/270\n",
      "215/270\n",
      "216/270\n",
      "217/270\n",
      "218/270\n",
      "219/270\n",
      "220/270\n",
      "221/270\n",
      "222/270\n",
      "223/270\n",
      "224/270\n",
      "225/270\n",
      "226/270\n",
      "227/270\n",
      "228/270\n",
      "229/270\n",
      "230/270\n",
      "231/270\n",
      "232/270\n",
      "233/270\n",
      "234/270\n",
      "235/270\n",
      "236/270\n",
      "237/270\n",
      "238/270\n",
      "239/270\n",
      "240/270\n",
      "241/270\n",
      "242/270\n",
      "243/270\n",
      "244/270\n",
      "245/270\n",
      "246/270\n",
      "247/270\n",
      "248/270\n",
      "249/270\n",
      "250/270\n",
      "251/270\n",
      "252/270\n",
      "253/270\n",
      "254/270\n",
      "255/270\n",
      "256/270\n",
      "257/270\n",
      "258/270\n",
      "259/270\n",
      "260/270\n",
      "261/270\n",
      "262/270\n",
      "263/270\n",
      "264/270\n",
      "265/270\n",
      "266/270\n",
      "267/270\n",
      "268/270\n",
      "269/270\n",
      "270/270\n",
      "✅ All images have been scaled to 512x512 and saved in data/processed/images\n"
     ]
    }
   ],
   "source": [
    "!python src/yolo/yolo_preprocess.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf64bd2",
   "metadata": {},
   "source": [
    "Kada se skripta izvrši, kreiraće se folder *images* unutar *data/processed* koji će sadržati slike dimenzija 512x512."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef0b435",
   "metadata": {},
   "source": [
    "### Skripta za podelu dataset-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9b7bb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset podeljen na train/val/test foldere.\n",
      "Train: 189, Val: 40, Test: 41\n"
     ]
    }
   ],
   "source": [
    "!python src/yolo/yolo_split_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8a381",
   "metadata": {},
   "source": [
    "Kada se skripta izvrši, kreiraće se folderi *train, val i test* unutar *data/processed* koji će sadržati podfoldere *images* i *labels*. U *images* folderu će se nalaziti slike dok će odgovarajuće labele biti u *labels* folderu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0f56d5",
   "metadata": {},
   "source": [
    "## 2. Treniranje YOLOv8 modela za detekciju novčanica  \n",
    "Cilj treniranja YOLOv8 modela jeste da model bude sposoban da detektuje prisustvo novčanice na slici kao i da odredi gde se ona nalazi.  \n",
    "Konfiguracija za treniranje modela se nalazi unutar *configs/data.yaml fajla*.\n",
    "```bash\n",
    "    nc: 1\n",
    "\n",
    "    names: [\"banknote\"]\n",
    "\n",
    "    train: ../data/processed/train/images\n",
    "    val: ../data/processed/val/images\n",
    "    test: ../data/processed/test/images\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb01b074",
   "metadata": {},
   "source": [
    "### Skripta za treniranje modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c182c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!python src/yolo/yolo_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7815e755",
   "metadata": {},
   "source": [
    "Kada se model istrenira, bice sačuvan unutar *runs/train/serbian_banknotes/weignts/best.pt*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5e433f",
   "metadata": {},
   "source": [
    "### Skripte za testiranje modela\n",
    "\n",
    "Postoje 2 skripte za testiranje. Jedna skripta ispisuje metrike modela dok druga vrši vizuelno testiranje tako što prikazuje slike sa novčanicama i na svakoj pokaže svoju predikciju gde se nalazi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951fa690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skripta koja prikazuje vednost metrika\n",
    "!python src/yolo/yolo_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfea29e",
   "metadata": {},
   "source": [
    "```bash\n",
    "=== Evaluation Metrics ===\n",
    "Precision (P):   0.999\n",
    "Recall (R):      1.000\n",
    "mAP@0.5:         0.995\n",
    "mAP@0.5:0.95:    0.921\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08705742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skripta za vizuelno testiranje\n",
    "!python src/yolo/yolo_test_bb.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59af6b2e",
   "metadata": {},
   "source": [
    "## 3. Priprema i pretprocesiranje dataset-a za treniranje CNN modela \n",
    "\n",
    "Pomoću našeg YOLO modela radimo kropovanje slika slika iz originalnog data seta koji se nalazi u *data/raw/images* i obrađene slike smeštamo unutar *data/processed/cnn/cnn_dataset*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354777d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/yolo/yolo_crop_images.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110fa124",
   "metadata": {},
   "source": [
    "Sada imamo dataset unutar *data/processed/cnn/cnn_dataset* koji je neophodno podeliti u podfoldere po vrednosti apoena a zatim podeliti na train/test/val grupe da bismo mogli da treniramo model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be8f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/cnn/cnn_sort_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b00f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/cnn/cnn_split_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd8d4ac",
   "metadata": {},
   "source": [
    "Ako je sve uspešno izvršeno, unutar *data/processed/cnn* foldera će se pojaviti *cnn_sorted* i *train, test i val* podfolderi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ccacf1",
   "metadata": {},
   "source": [
    "## 4. Treniranje CNN modela za klasifikaciju apoena  \n",
    "\n",
    "Cilj treniranja CNN modela jeste dobiti model koji je sposoban da klasifikuje novčanice na osnovu vrednosti novčanice.\n",
    "\n",
    "### Konfiguracije \n",
    "``` bash\n",
    "{\n",
    "  \"data\": {\n",
    "    \"train_dir\": \"./data/processed/cnn/train\",\n",
    "    \"val_dir\": \"./data/processed/cnn/val\",\n",
    "    \"test_dir\": \"./data/processed/cnn/test\"\n",
    "  },\n",
    "  \"model\": {\n",
    "    \"save_dir\": \"cnn_model\",\n",
    "    \"weights_file\": \"serbian_banknote_cnn.pth\",\n",
    "    \"img_size\": 256\n",
    "  },\n",
    "  \"classes\": [\"10\", \"20\", \"50\", \"100\", \"200\", \"500\", \"1000\", \"2000\", \"5000\"],\n",
    "  \"training\": {\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 0.001,\n",
    "    \"num_epochs\": 50\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "### Model\n",
    "``` bash\n",
    "class SerbianBanknoteCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(128*30*30, 256) \n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.feature_extraction(x)        \n",
    "        x = x.view(x.size(0), -1)              \n",
    "        x = self.dropout(F.relu(self.fc1(x)))   \n",
    "        x = self.fc2(x)                         \n",
    "        return x\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b9fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/cnn/cnn_train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60faf77b",
   "metadata": {},
   "source": [
    "```bash\n",
    "Epoch [1/50] Train Loss: 2.8038 Val Loss: 2.1908 Val Acc: 11.11%\n",
    "✅ Best model saved at epoch 1 with Val Acc: 11.11%\n",
    "Epoch [2/50] Train Loss: 2.1706 Val Loss: 2.0786 Val Acc: 16.67%\n",
    "✅ Best model saved at epoch 2 with Val Acc: 16.67%\n",
    "Epoch [3/50] Train Loss: 2.0407 Val Loss: 1.8415 Val Acc: 38.89%\n",
    "✅ Best model saved at epoch 3 with Val Acc: 38.89%\n",
    "Epoch [4/50] Train Loss: 1.7591 Val Loss: 1.5717 Val Acc: 47.22%\n",
    "✅ Best model saved at epoch 4 with Val Acc: 47.22%\n",
    "Epoch [5/50] Train Loss: 1.3322 Val Loss: 1.0311 Val Acc: 55.56%\n",
    "✅ Best model saved at epoch 5 with Val Acc: 55.56%\n",
    "Epoch [6/50] Train Loss: 0.9976 Val Loss: 1.2348 Val Acc: 61.11%\n",
    "✅ Best model saved at epoch 6 with Val Acc: 61.11%\n",
    "Epoch [7/50] Train Loss: 0.7860 Val Loss: 0.6087 Val Acc: 69.44%\n",
    "✅ Best model saved at epoch 7 with Val Acc: 69.44%\n",
    "Epoch [8/50] Train Loss: 0.5197 Val Loss: 0.5022 Val Acc: 77.78%\n",
    "✅ Best model saved at epoch 8 with Val Acc: 77.78%\n",
    "Epoch [9/50] Train Loss: 0.4516 Val Loss: 0.5131 Val Acc: 80.56%\n",
    "✅ Best model saved at epoch 9 with Val Acc: 80.56%\n",
    "Epoch [10/50] Train Loss: 0.1987 Val Loss: 0.5757 Val Acc: 75.00%\n",
    "Epoch [11/50] Train Loss: 0.1575 Val Loss: 0.5002 Val Acc: 83.33%\n",
    "✅ Best model saved at epoch 11 with Val Acc: 83.33%\n",
    "Epoch [12/50] Train Loss: 0.1479 Val Loss: 0.4001 Val Acc: 91.67%\n",
    "✅ Best model saved at epoch 12 with Val Acc: 91.67%\n",
    "Epoch [13/50] Train Loss: 0.0769 Val Loss: 0.5142 Val Acc: 80.56%\n",
    "Epoch [14/50] Train Loss: 0.0504 Val Loss: 0.4931 Val Acc: 88.89%\n",
    "...\n",
    "Epoch [47/50] Train Loss: 0.0015 Val Loss: 0.5832 Val Acc: 88.89%\n",
    "Epoch [48/50] Train Loss: 0.0015 Val Loss: 0.5781 Val Acc: 88.89%\n",
    "Epoch [49/50] Train Loss: 0.0011 Val Loss: 0.5734 Val Acc: 88.89%\n",
    "Epoch [50/50] Train Loss: 0.0041 Val Loss: 0.5855 Val Acc: 86.11%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25126834",
   "metadata": {},
   "source": [
    "Posle uspešno završenog testiranja CNN model će biti sačuvan u *cnn_model/* folderu kao *serbian_banknote_cnn.pth*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc53b4",
   "metadata": {},
   "source": [
    "### Skripta za prikaz metrika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b447c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/cnn/cnn_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd076ee3",
   "metadata": {},
   "source": [
    "## 5. Kombinovanje YOLO + CNN modela za prepoznavanje srpskih novčanica\n",
    "\n",
    "Sada je na redu da se testira kako ova dva modela rade zajedno. Za to je neophodno pokrenuti *main.py* u terminalu kao što je napisano.\n",
    "### Tok:\n",
    "- učitavamo yolo i cnn modele\n",
    "- unosimo putanju do slike novčanice\n",
    "- dobijamo predikciju\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34115946",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/main.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
